# Candidate Instructions

Thank you for taking this challenge! Please read carefully before starting.

---

## Timebox

**Budget about 3 hours.** The AI will handle scaffolding quickly — we're evaluating what you choose to focus on and how you guide the process. Depth on a few tasks beats shallow coverage across many. Stop when you feel you've shown your best work.

---

## What to Build

1. Get the project running (see [`README.md`](README.md) for setup, data model, endpoints, and available infrastructure).
2. Implement the basic endpoints described in `README.md`.
3. Pick items from the **Advanced Task Menu** in [`ADVANCED_TASKS.md`](ADVANCED_TASKS.md):
   - **2–3 Product Features** (Category A) — visible, demo-worthy functionality.
   - **1–2 Engineering Excellence** tasks (Category B) — algorithms, performance, reliability, or API craft.

*NOTE:* Feel free to break out of the Advanced Task Menu items.  The opportunities are endless here, feel free to use your imagination to do something you feel fits and will show off your skills.

---

## Third-Party Services

Several advanced tasks involve external APIs (OpenAI, Facebook, Mux, etc.). **Free tiers and sandbox modes are sufficient** for this challenge. If you prefer not to sign up for a service, a well-implemented **mock/fallback** is perfectly acceptable — we care about the integration architecture, not whether you have a live API key.

---

## Deliverables

- Working code for the chosen tasks.
- Tests demonstrating correctness (unit + feature; property-based or concurrency tests where relevant).
- Any supporting artifacts for your chosen tasks (e.g., OpenAPI spec, ADR, migration files).
- *(Optional but encouraged)* A short screen recording or screenshots demonstrating your advanced features in action.
- A short **AI Usage Report** (`ai/README.md`) including:
  - The 3 best prompts you used.
  - At least 1 place where the AI was wrong and how you fixed it.
  - Notes on what you edited vs. accepted.

---

## Using AI

- You are **encouraged** to use an AI coding agent (ChatGPT, Claude Code, etc.).
- Treat the AI as a collaborator, not an autopilot.
- Do **not** paste any secrets into prompts.
- Always test and verify generated code.
- Prefer small iterations (don't ask the AI to build the whole project at once).

---

## Evaluation Rubric (0–4 each, 40 points total)

1. **Correctness** — endpoints work as specified.
2. **Algorithmic clarity** — autopost rationale is testable, reproducible.
3. **Product Feature Quality** — advanced features produce working, demo-worthy results.
4. **Integration Craft** — external APIs/services integrated cleanly with error handling and fallbacks.
5. **API Design** — consistent response shapes, proper HTTP semantics, documentation.
6. **Testing depth** — thoughtful coverage of happy paths, failure paths, and edge cases.
7. **Architecture** — separation of concerns, service extraction, appropriate use of Laravel features.
8. **Data Modeling** — schema design, migrations, relationships, validation.
9. **AI collaboration quality** — prompts, fixes, reflection.
10. **Overall polish** — naming, consistency, readability.

---

## Submission

When complete, push your code to a public or private repo and share the link.
